Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.06122131645679474
Distance: 1.8827259540557861
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.04739288240671158
Distance: 1.8645167350769043
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.13877207040786743
Distance: 1.8566656112670898
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.03194954991340637
Distance: 1.8171991109848022
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.12195812165737152
Distance: 1.8379015922546387
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.1390525996685028
Distance: 1.8288205862045288
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 3, 0, 0])
Action: noop
Reward: -0.10039621591567993
Distance: 1.8284040689468384
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 3, 0, 0])
Action: right
Reward: -0.06906664371490479
Distance: 1.8611712455749512
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.1537931263446808
Distance: 1.8664495944976807
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.09788668155670166
Distance: 1.8588556051254272
Next state: tensor([2, 2, 0, 0])
================================================================================

