Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09459734708070755
Distance: 0.004150428343564272
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.10106600821018219
Distance: 0.00420401431620121
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09954587370157242
Distance: 0.004107964690774679
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09791459143161774
Distance: 0.004122639074921608
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09580166637897491
Distance: 0.004172118846327066
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.10442468523979187
Distance: 0.004182233475148678
Next state: tensor([3, 2, 1, 0])
================================================================================

