Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.06719321012496948
Distance: 0.1438101977109909
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.11709056794643402
Distance: 0.1449599415063858
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.07836033403873444
Distance: 0.1413487195968628
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10234526544809341
Distance: 0.13878241181373596
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.06134907901287079
Distance: 0.1344815492630005
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.08590888977050781
Distance: 0.12801073491573334
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1223265528678894
Distance: 0.12865261733531952
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.14686985313892365
Distance: 0.12878650426864624
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09203463792800903
Distance: 0.12894341349601746
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.060774028301239014
Distance: 0.13854338228702545
Next state: tensor([2, 2, 0, 0])
================================================================================

