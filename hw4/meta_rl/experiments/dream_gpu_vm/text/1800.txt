Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.07017175108194351
Distance: 0.7439253926277161
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.1398429125547409
Distance: 0.7640659809112549
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.13097476959228516
Distance: 0.7427985668182373
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.10094457864761353
Distance: 0.7340343594551086
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.0858767032623291
Distance: 0.7846940755844116
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 0, 0, 0])
Action: end_episode
Reward: -0.0810481384396553
Distance: 0.8159975409507751
Next state: tensor([2, 0, 0, 0])
================================================================================

