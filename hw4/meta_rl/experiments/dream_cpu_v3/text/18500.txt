Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: nan
Distance: 3.626029138104059e-05
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: left
Reward: nan
Distance: 3.903925244230777e-05
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 3, 0, 0])
Action: left
Reward: nan
Distance: 4.177996015641838e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 3, 0, 0])
Action: left
Reward: -14.096475601196289
Distance: 4.414823342813179e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 3, 0, 0])
Action: left
Reward: nan
Distance: 4.335928679211065e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 3, 0, 0])
Action: left
Reward: nan
Distance: 4.3699463276425377e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 3, 0, 0])
Action: left
Reward: nan
Distance: 4.389967580209486e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 3, 0, 0])
Action: left
Reward: nan
Distance: 4.416262891027145e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 3, 0, 0])
Action: left
Reward: nan
Distance: 4.442827412276529e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 3, 0, 0])
Action: left
Reward: nan
Distance: 4.4642667489824817e-05
Next state: tensor([0, 3, 0, 0])
================================================================================

