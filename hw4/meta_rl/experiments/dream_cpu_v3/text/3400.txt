Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -5.997701644897461
Distance: 0.07247664779424667
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -5.971457004547119
Distance: 0.0695289894938469
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: left
Reward: nan
Distance: 0.06651169061660767
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: pickup
Reward: nan
Distance: 0.06749583035707474
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0, 0])
Action: left
Reward: -6.944653511047363
Distance: 0.07372727990150452
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 0, 0])
Action: pickup
Reward: nan
Distance: 0.07258129119873047
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 0, 0])
Action: ride_bus
Reward: nan
Distance: 0.07630380988121033
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0, 0])
Action: left
Reward: -6.13433313369751
Distance: 0.07678419351577759
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 0, 0])
Action: left
Reward: -6.8577728271484375
Distance: 0.07420120388269424
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 1, 0, 0])
Action: left
Reward: -7.744094371795654
Distance: 0.07295069098472595
Next state: tensor([0, 1, 0, 0])
================================================================================

