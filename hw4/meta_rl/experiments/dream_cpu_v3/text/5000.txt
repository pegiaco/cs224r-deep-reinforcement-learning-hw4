Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.010309106670320034
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: nan
Distance: 0.010756567120552063
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.011057263240218163
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.011080893687903881
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: down
Reward: -8.142304420471191
Distance: 0.011235644109547138
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 0, 0])
Action: left
Reward: -8.285120964050293
Distance: 0.01091049239039421
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 0, 0])
Action: left
Reward: -8.962359428405762
Distance: 0.01062872726470232
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0, 0])
Action: up
Reward: nan
Distance: 0.010485612787306309
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.010765913873910904
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: up
Reward: -8.821280479431152
Distance: 0.011228379793465137
Next state: tensor([0, 3, 0, 0])
================================================================================

