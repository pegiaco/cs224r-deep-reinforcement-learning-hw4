Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -8.006134986877441
Distance: 0.4514933228492737
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -6.142704963684082
Distance: 0.45091477036476135
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -5.681251049041748
Distance: 0.4471933841705322
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: nan
Distance: 0.4413181245326996
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 4])
Action: ride_bus
Reward: nan
Distance: 0.4490618407726288
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 4])
Action: end_episode
Reward: nan
Distance: 0.46995359659194946
Next state: tensor([4, 2, 0, 4])
================================================================================

