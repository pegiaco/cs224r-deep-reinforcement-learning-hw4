Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -9.69587230682373
Distance: 0.0010963098611682653
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: -13.269796371459961
Distance: 0.001028220634907484
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.0010263302829116583
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: left
Reward: -11.271700859069824
Distance: 0.0010591101599857211
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: left
Reward: -10.331958770751953
Distance: 0.0010450453264638782
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: left
Reward: -11.02180004119873
Distance: 0.0010090224677696824
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: left
Reward: -11.891345977783203
Distance: 0.0009909706423059106
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: left
Reward: -12.92887020111084
Distance: 0.000983341014944017
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: left
Reward: -15.349238395690918
Distance: 0.0009807059541344643
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.0009804262081161141
Next state: tensor([0, 2, 0, 0])
================================================================================

