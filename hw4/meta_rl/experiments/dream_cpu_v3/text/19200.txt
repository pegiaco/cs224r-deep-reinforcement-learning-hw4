Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: nan
Distance: 9.081144526135176e-05
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: nan
Distance: 9.744010458234698e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: left
Reward: -13.269796371459961
Distance: 0.00010687239409890026
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: left
Reward: -14.337637901306152
Distance: 0.00010500392090762034
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: down
Reward: nan
Distance: 0.00010435641161166131
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 1, 0, 0])
Action: left
Reward: -11.939742088317871
Distance: 0.00011894883209606633
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 1, 0, 0])
Action: left
Reward: nan
Distance: 0.00011178859858773649
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0, 0])
Action: left
Reward: nan
Distance: 0.00011266799265285954
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 0, 0])
Action: left
Reward: nan
Distance: 0.00011356389586580917
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 1, 0, 0])
Action: left
Reward: nan
Distance: 0.00011408496357034892
Next state: tensor([0, 1, 0, 0])
================================================================================

