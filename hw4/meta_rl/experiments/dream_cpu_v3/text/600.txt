Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -24.70313835144043
Distance: 26.057851791381836
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -27.06283187866211
Distance: 24.393308639526367
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: left
Reward: nan
Distance: 24.31952667236328
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: left
Reward: nan
Distance: 24.44347381591797
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0, 0])
Action: right
Reward: -29.862014770507812
Distance: 24.485355377197266
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: down
Reward: -27.328638076782227
Distance: 24.48025894165039
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0, 0])
Action: drop
Reward: nan
Distance: 24.418193817138672
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: noop
Reward: nan
Distance: 24.4451847076416
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 0, 0, 0])
Action: drop
Reward: -28.30990219116211
Distance: 24.5
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: pickup
Reward: -27.249948501586914
Distance: 24.475814819335938
Next state: tensor([1, 0, 0, 0])
================================================================================

