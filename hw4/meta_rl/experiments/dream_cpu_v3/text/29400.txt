Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: nan
Distance: 8.897646694094874e-06
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: -14.78962230682373
Distance: 9.884834071272053e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: left
Reward: -14.656091690063477
Distance: 9.424371455679648e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.04238510131836
Distance: 8.985044587461744e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.735532760620117
Distance: 8.850716767483391e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.04238510131836
Distance: 8.760206583247054e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.735532760620117
Distance: 8.68931965669617e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: left
Reward: -inf
Distance: 8.657145372126251e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: left
Reward: -inf
Distance: 8.648903531138785e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: left
Reward: -inf
Distance: 8.652482392790262e-06
Next state: tensor([0, 2, 0, 0])
================================================================================

