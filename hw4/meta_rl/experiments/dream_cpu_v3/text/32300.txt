Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: nan
Distance: 2.2833797629573382e-05
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: nan
Distance: 2.420758937660139e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: nan
Distance: 2.460330506437458e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 2.526973548810929e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.735532760620117
Distance: 2.6655025067157112e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: left
Reward: -15.349238395690918
Distance: 2.659486017364543e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: left
Reward: -14.94377326965332
Distance: 2.6282668841304258e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.735532760620117
Distance: 2.602387212391477e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.04238510131836
Distance: 2.586823029560037e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: left
Reward: -16.735532760620117
Distance: 2.5789138817344792e-05
Next state: tensor([0, 2, 0, 0])
================================================================================

