Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: -7.464943885803223
Distance: 0.030990414321422577
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: left
Reward: -9.031622886657715
Distance: 0.03033769689500332
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: nan
Distance: 0.030201470479369164
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 2, 0, 0])
Action: noop
Reward: -6.988990783691406
Distance: 0.03231307119131088
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 2, 0, 0])
Action: right
Reward: nan
Distance: 0.03126123175024986
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: drop
Reward: -7.878159523010254
Distance: 0.031919509172439575
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: left
Reward: -7.587492942810059
Distance: 0.031487174332141876
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: left
Reward: -7.7714762687683105
Distance: 0.030909426510334015
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: up
Reward: nan
Distance: 0.030428944155573845
Next state: tensor([0, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 3, 0, 0])
Action: up
Reward: -7.589623928070068
Distance: 0.03054504096508026
Next state: tensor([0, 4, 1, 0])
================================================================================

