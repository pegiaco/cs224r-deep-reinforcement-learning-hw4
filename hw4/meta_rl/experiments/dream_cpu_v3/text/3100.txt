Env ID: [22]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: nan
Distance: 0.019484899938106537
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.019878113642334938
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: right
Reward: -6.840177536010742
Distance: 0.020399518311023712
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: left
Reward: -8.378039360046387
Distance: 0.019193479791283607
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: left
Reward: nan
Distance: 0.01893448643386364
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([0, 2, 0, 0])
Action: drop
Reward: -8.711980819702148
Distance: 0.019641349092125893
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.019455861300230026
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: ride_bus
Reward: -6.621824264526367
Distance: 0.019499626010656357
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 2, 0, 0])
Action: left
Reward: nan
Distance: 0.018000800162553787
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 2, 0, 0])
Action: pickup
Reward: -7.622694492340088
Distance: 0.018455687910318375
Next state: tensor([0, 2, 0, 0])
================================================================================

