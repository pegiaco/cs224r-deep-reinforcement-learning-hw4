Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0913301482796669
Distance: 8.324545860290527
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.20649528503418
Distance: 8.315876007080078
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 5])
Action: left
Reward: -0.09364872425794601
Distance: 0.009380153380334377
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09999154508113861
Distance: 0.0030288794077932835
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09966641664505005
Distance: 0.003020423697307706
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10113538801670074
Distance: 0.0026868367567658424
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.0996956154704094
Distance: 0.0038222260773181915
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.10114976763725281
Distance: 0.0035178386606276035
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: ride_bus
Reward: -0.10111142694950104
Distance: 0.004667602013796568
Next state: tensor([0, 4, 1, 0])
================================================================================

