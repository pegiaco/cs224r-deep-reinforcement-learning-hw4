Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1002565398812294
Distance: 9.336555480957031
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.22441577911377
Distance: 9.336812019348145
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 8])
Action: down
Reward: -0.09455668181180954
Distance: 0.012395987287163734
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09917307645082474
Distance: 0.00695266667753458
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.09965629130601883
Distance: 0.006125739775598049
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09632322937250137
Distance: 0.005782028194516897
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.10024949908256531
Distance: 0.002105258870869875
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: pickup
Reward: -0.10228697210550308
Distance: 0.002354753902181983
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.09865523874759674
Distance: 0.004641724284738302
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 0, 0, 0])
Action: noop
Reward: -0.10263422876596451
Distance: 0.003296962007880211
Next state: tensor([2, 0, 0, 0])
================================================================================

