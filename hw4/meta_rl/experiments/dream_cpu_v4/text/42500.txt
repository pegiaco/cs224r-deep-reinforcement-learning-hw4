Env ID: [12]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08814249187707901
Distance: 7.109723091125488
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 6.985208511352539
Distance: 7.097865581512451
Next state: tensor([ 4,  2,  0, 13])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 13])
Action: left
Reward: -0.0986938327550888
Distance: 0.01265718787908554
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10116029530763626
Distance: 0.011351020075380802
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.10061944276094437
Distance: 0.01251131109893322
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 4, 0, 0])
Action: down
Reward: -0.09938888251781464
Distance: 0.013130749575793743
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.10073854774236679
Distance: 0.012519629672169685
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0, 0])
Action: down
Reward: -0.09973569214344025
Distance: 0.013258173130452633
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: end_episode
Reward: -0.10018660128116608
Distance: 0.012993862852454185
Next state: tensor([3, 3, 0, 0])
================================================================================

