Env ID: [17]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.04330406337976456
Distance: 8.487154960632324
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.325382232666016
Distance: 8.430459022521973
Next state: tensor([ 4,  2,  0, 18])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 18])
Action: left
Reward: -0.0977514311671257
Distance: 0.005076650530099869
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09954385459423065
Distance: 0.0028280781116336584
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09880001097917557
Distance: 0.0023719328455626965
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10064234584569931
Distance: 0.0011719416361302137
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10031449049711227
Distance: 0.0018142879707738757
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: up
Reward: -0.09893176704645157
Distance: 0.0021287761628627777
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 3, 0, 0])
Action: end_episode
Reward: -0.10078983008861542
Distance: 0.0010605399729683995
Next state: tensor([1, 3, 0, 0])
================================================================================

