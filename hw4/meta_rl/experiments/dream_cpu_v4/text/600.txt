Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: 1.4525054693222046
Distance: 26.07828712463379
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.021133042871952057
Distance: 24.525781631469727
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 1, 0, 0])
Action: left
Reward: -0.22474822402000427
Distance: 24.446914672851562
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.1372600495815277
Distance: 24.57166290283203
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([0, 1, 0, 0])
Action: right
Reward: -0.09812698513269424
Distance: 24.608922958374023
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 1, 0, 0])
Action: down
Reward: -0.024352647364139557
Distance: 24.6070499420166
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 0, 0, 0])
Action: drop
Reward: -0.1404777467250824
Distance: 24.531402587890625
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 0, 0, 0])
Action: noop
Reward: -0.14530906081199646
Distance: 24.571880340576172
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 0, 0, 0])
Action: drop
Reward: -0.08368263393640518
Distance: 24.617189407348633
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: pickup
Reward: -0.035115815699100494
Distance: 24.600872039794922
Next state: tensor([1, 0, 0, 0])
================================================================================

