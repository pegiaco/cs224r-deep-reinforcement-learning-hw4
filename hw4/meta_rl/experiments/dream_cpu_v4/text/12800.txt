Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.16263923048973083
Distance: 8.302313804626465
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.188694566488266
Distance: 8.36495304107666
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.329700469970703
Distance: 8.45364761352539
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.08689852058887482
Distance: 0.023946447297930717
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09849100559949875
Distance: 0.010844963602721691
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10238253325223923
Distance: 0.009335970506072044
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.0940350741147995
Distance: 0.011718503199517727
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10121621936559677
Distance: 0.005753573030233383
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.1014333963394165
Distance: 0.006969793699681759
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.10334254801273346
Distance: 0.008403189480304718
Next state: tensor([2, 3, 1, 0])
================================================================================

