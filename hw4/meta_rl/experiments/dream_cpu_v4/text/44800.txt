Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.2448960244655609
Distance: 7.9245781898498535
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.04424343258142471
Distance: 8.069474220275879
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.07359037548303604
Distance: 8.013717651367188
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.007047273218631744
Distance: 7.987308025360107
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.049526311457157135
Distance: 7.894355297088623
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.10373983532190323
Distance: 7.843881607055664
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: up
Reward: 7.739694595336914
Distance: 7.847621440887451
Next state: tensor([4, 2, 0, 4])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 4])
Action: left
Reward: -0.09339877218008041
Distance: 0.007927065715193748
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: end_episode
Reward: -0.09941686689853668
Distance: 0.001325836288742721
Next state: tensor([3, 2, 1, 0])
================================================================================

