Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.11722145229578018
Distance: 8.377237319946289
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09088096767663956
Distance: 8.394458770751953
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: pickup
Reward: -0.04089317470788956
Distance: 8.385339736938477
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.200859069824219
Distance: 8.32623291015625
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 22])
Action: left
Reward: -0.08805016428232193
Distance: 0.025373907759785652
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09478125721216202
Distance: 0.013424071483314037
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.10247990489006042
Distance: 0.008205325342714787
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.0975523516535759
Distance: 0.010685226880013943
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.1027771383523941
Distance: 0.008237577974796295
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10321129113435745
Distance: 0.01101471297442913
Next state: tensor([1, 2, 1, 0])
================================================================================

