Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11327610164880753
Distance: 8.683587074279785
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.836095333099365
Distance: 8.696863174438477
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 7])
Action: drop
Reward: 0.5000301599502563
Distance: 0.7607681155204773
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 7])
Action: ride_bus
Reward: -0.13000914454460144
Distance: 0.16073793172836304
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.0626443549990654
Distance: 0.19074706733226776
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.07808021456003189
Distance: 0.15339142084121704
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10021700710058212
Distance: 0.1314716339111328
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10140017420053482
Distance: 0.13168863952159882
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09948905557394028
Distance: 0.13308881223201752
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.10418400913476944
Distance: 0.13257786631584167
Next state: tensor([2, 2, 0, 0])
================================================================================

