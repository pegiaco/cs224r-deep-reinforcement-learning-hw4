Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.09751453250646591
Distance: 9.041389465332031
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.13050422072410583
Distance: 8.84387493133545
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.05509529262781143
Distance: 8.87437915802002
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.726865768432617
Distance: 8.829474449157715
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 8])
Action: down
Reward: -0.09943738579750061
Distance: 0.0026083055417984724
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09985519200563431
Distance: 0.0020456912461668253
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 1, 0, 0])
Action: down
Reward: -0.10025382786989212
Distance: 0.0019008821109309793
Next state: tensor([3, 0, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 0, 0, 0])
Action: left
Reward: -0.09916297346353531
Distance: 0.00215470721013844
Next state: tensor([2, 0, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 0, 0, 0])
Action: left
Reward: -0.10049517452716827
Distance: 0.0013176826760172844
Next state: tensor([1, 0, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 0, 0, 0])
Action: left
Reward: -0.1004091128706932
Distance: 0.0018128572264686227
Next state: tensor([0, 0, 1, 0])
================================================================================

