Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: left
Reward: 0.05207624286413193
Distance: 7.264854907989502
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: 0.0923699364066124
Distance: 7.112778663635254
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.006161309778690338
Distance: 6.920408725738525
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.052050210535526276
Distance: 6.8265700340271
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 2, 1, 0])
Action: pickup
Reward: -0.07458076626062393
Distance: 6.77862024307251
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.18540677428245544
Distance: 6.753201007843018
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: down
Reward: -0.3608594834804535
Distance: 6.8386077880859375
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 1, 0, 0])
Action: noop
Reward: -0.40319928526878357
Distance: 7.0994672775268555
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.3929048478603363
Distance: 7.4026665687561035
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([0, 1, 0, 0])
Action: left
Reward: -0.268624871969223
Distance: 7.695571422576904
Next state: tensor([0, 1, 0, 0])
================================================================================

