Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11618099361658096
Distance: 8.318526268005371
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.187148094177246
Distance: 8.334707260131836
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 22])
Action: down
Reward: -0.06606502830982208
Distance: 0.047558560967445374
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.10276385396718979
Distance: 0.013623584061861038
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.09698173403739929
Distance: 0.01638743467628956
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.09851053357124329
Distance: 0.013369163498282433
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.10409814119338989
Distance: 0.011879696510732174
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.1051948070526123
Distance: 0.015977835282683372
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.10503870248794556
Distance: 0.021172644570469856
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.1048813909292221
Distance: 0.026211343705654144
Next state: tensor([2, 1, 1, 0])
================================================================================

