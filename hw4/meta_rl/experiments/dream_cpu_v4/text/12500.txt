Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.05162773281335831
Distance: 9.70493221282959
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.06397495418787003
Distance: 9.656559944152832
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.493721961975098
Distance: 9.620534896850586
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 2])
Action: left
Reward: -0.08503688126802444
Distance: 0.02681262046098709
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10166477411985397
Distance: 0.011849500238895416
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09538552910089493
Distance: 0.013514273799955845
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09863220900297165
Distance: 0.00889979861676693
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.10015581548213959
Distance: 0.007532005198299885
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.09874864667654037
Distance: 0.007687821052968502
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 3, 0, 0])
Action: drop
Reward: -0.10041369497776031
Distance: 0.006436467636376619
Next state: tensor([3, 3, 0, 0])
================================================================================

