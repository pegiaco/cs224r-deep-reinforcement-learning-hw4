Env ID: [2]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.03942833095788956
Distance: 8.757716178894043
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.595563888549805
Distance: 8.697144508361816
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 2
State: tensor([4, 2, 0, 3])
Action: drop
Reward: -0.0996832549571991
Distance: 0.0015805212315171957
Next state: tensor([4, 2, 0, 3])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 3])
Action: left
Reward: -0.10019068419933319
Distance: 0.0012637748150154948
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.09939899295568466
Distance: 0.0014544560108333826
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.09986239671707153
Distance: 0.0008534493390470743
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.10032816976308823
Distance: 0.0007158475345931947
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0, 0])
Action: left
Reward: -0.10018815100193024
Distance: 0.0010440131882205606
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 4, 0, 0])
Action: pickup
Reward: -0.10037099570035934
Distance: 0.001232160720974207
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 4, 0, 0])
Action: left
Reward: -0.10038742423057556
Distance: 0.0016031513223424554
Next state: tensor([1, 4, 0, 0])
================================================================================

