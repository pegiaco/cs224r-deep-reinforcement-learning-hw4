Env ID: [17]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.08077392727136612
Distance: 8.133228302001953
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.09252224117517471
Distance: 8.114002227783203
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.9634222984313965
Distance: 8.106524467468262
Next state: tensor([ 4,  2,  0, 18])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 18])
Action: left
Reward: -0.06996573507785797
Distance: 0.0431024543941021
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10389508306980133
Distance: 0.013068192638456821
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09807778149843216
Distance: 0.01696327142417431
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.11495542526245117
Distance: 0.015041053295135498
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.11567451804876328
Distance: 0.0299964789301157
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.12331801652908325
Distance: 0.045670993626117706
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.13557425141334534
Distance: 0.06898900866508484
Next state: tensor([1, 2, 1, 0])
================================================================================

