Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.14940890669822693
Distance: 8.133743286132812
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.18470057845115662
Distance: 8.183152198791504
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.14249572157859802
Distance: 8.267852783203125
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.33509883284568787
Distance: 8.310348510742188
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: up
Reward: 8.438055992126465
Distance: 8.54544734954834
Next state: tensor([ 4,  2,  0, 12])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 12])
Action: end_episode
Reward: -0.09512530267238617
Distance: 0.007390759885311127
Next state: tensor([ 4,  2,  0, 12])
================================================================================

