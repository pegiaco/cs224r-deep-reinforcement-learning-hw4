Env ID: [19]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.22362098097801208
Distance: 8.777362823486328
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.19187220931053162
Distance: 8.900983810424805
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.23038825392723083
Distance: 8.9928560256958
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 3, 0, 0])
Action: drop
Reward: -0.0663658156991005
Distance: 9.123244285583496
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 3, 0, 0])
Action: up
Reward: -0.08471927791833878
Distance: 9.08961009979248
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 4, 0, 0])
Action: pickup
Reward: -0.09861812740564346
Distance: 9.074329376220703
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 4, 0, 0])
Action: noop
Reward: -0.24566039443016052
Distance: 9.07294750213623
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 4, 0, 0])
Action: up
Reward: -0.051717378199100494
Distance: 9.218607902526855
Next state: tensor([1, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 4, 0, 0])
Action: end_episode
Reward: -0.04983577877283096
Distance: 9.17032527923584
Next state: tensor([1, 4, 0, 0])
================================================================================

