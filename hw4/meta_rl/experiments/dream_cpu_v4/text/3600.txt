Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: 0.08485259860754013
Distance: 8.761295318603516
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.14791926741600037
Distance: 8.57644271850586
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07223091274499893
Distance: 8.624361991882324
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 1.45927894115448
Distance: 8.596592903137207
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 15])
Action: noop
Reward: 1.1430562734603882
Distance: 7.037313938140869
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 5
State: tensor([ 4,  2,  0, 15])
Action: left
Reward: -0.12243948131799698
Distance: 5.794257640838623
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.06457243114709854
Distance: 5.816697120666504
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 15])
Action: end_episode
Reward: 0.03631296008825302
Distance: 5.781269550323486
Next state: tensor([ 4,  2,  0, 15])
================================================================================

