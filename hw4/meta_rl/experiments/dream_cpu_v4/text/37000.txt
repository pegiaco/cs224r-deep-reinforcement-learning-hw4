Env ID: [4]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.023783303797245026
Distance: 8.102723121643066
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.018849946558475494
Distance: 8.026506423950195
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.10498056560754776
Distance: 7.945356369018555
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.06779537349939346
Distance: 7.950336933135986
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.10943422466516495
Distance: 7.918132305145264
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.09756097942590714
Distance: 7.9275665283203125
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: up
Reward: 7.821653366088867
Distance: 7.9251275062561035
Next state: tensor([4, 2, 0, 5])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 5])
Action: end_episode
Reward: -0.0979057177901268
Distance: 0.0034742846619337797
Next state: tensor([4, 2, 0, 5])
================================================================================

