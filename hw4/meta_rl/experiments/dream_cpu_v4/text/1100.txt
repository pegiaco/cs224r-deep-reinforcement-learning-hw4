Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.006918527185916901
Distance: 8.72068977355957
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.1481538712978363
Distance: 8.627608299255371
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.0089326873421669
Distance: 8.675762176513672
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([1, 1, 0, 0])
Action: noop
Reward: -0.06673488765954971
Distance: 8.584694862365723
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.05193386226892471
Distance: 8.551429748535156
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: noop
Reward: -0.03188667446374893
Distance: 8.503363609313965
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.1120210662484169
Distance: 8.435250282287598
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 1, 0, 0])
Action: up
Reward: -0.15495261549949646
Distance: 8.447271347045898
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: down
Reward: -0.07601699978113174
Distance: 8.50222396850586
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 1, 0, 0])
Action: left
Reward: -0.10410747677087784
Distance: 8.478240966796875
Next state: tensor([2, 1, 1, 0])
================================================================================

