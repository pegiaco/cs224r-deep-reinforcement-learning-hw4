Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.1306358277797699
Distance: 9.282312393188477
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.05520210415124893
Distance: 9.312948226928711
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.141841888427734
Distance: 9.268150329589844
Next state: tensor([ 4,  2,  0, 10])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 10])
Action: left
Reward: -0.08058017492294312
Distance: 0.026308435946702957
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09933188557624817
Distance: 0.006888611242175102
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.10043193399906158
Distance: 0.006220492068678141
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.09890171885490417
Distance: 0.0066524227149784565
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10140279680490494
Distance: 0.005554141942411661
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10154576599597931
Distance: 0.006956933997571468
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10139132291078568
Distance: 0.008502698503434658
Next state: tensor([1, 2, 1, 0])
================================================================================

