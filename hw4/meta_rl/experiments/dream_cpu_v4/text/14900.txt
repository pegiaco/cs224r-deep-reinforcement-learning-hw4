Env ID: [6]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.14318189024925232
Distance: 7.615157604217529
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1407671868801117
Distance: 7.658339500427246
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 7.56882381439209
Distance: 7.699106693267822
Next state: tensor([4, 2, 0, 7])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 7])
Action: left
Reward: -0.07518855482339859
Distance: 0.03028314933180809
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10611706227064133
Distance: 0.005471702665090561
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.09668339043855667
Distance: 0.011588765308260918
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09832647442817688
Distance: 0.008272155188024044
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10160130262374878
Distance: 0.006598625332117081
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10062069445848465
Distance: 0.008199924603104591
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 2, 1, 0])
Action: right
Reward: -0.09802742302417755
Distance: 0.008820619434118271
Next state: tensor([2, 2, 0, 0])
================================================================================

