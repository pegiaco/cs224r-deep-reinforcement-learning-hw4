Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.26041945815086365
Distance: 7.654025077819824
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.23659858107566833
Distance: 7.814444541931152
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.12445221096277237
Distance: 7.951043128967285
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.24842795729637146
Distance: 7.975495338439941
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1672883927822113
Distance: 8.123923301696777
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.19098243117332458
Distance: 8.191211700439453
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.06538448482751846
Distance: 8.282194137573242
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.065640449523926
Distance: 8.247578620910645
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 2, 0, 6])
Action: pickup
Reward: -0.028424985706806183
Distance: 0.08193790167570114
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 6])
Action: left
Reward: -0.10099370032548904
Distance: 0.010362882167100906
Next state: tensor([3, 2, 1, 0])
================================================================================

